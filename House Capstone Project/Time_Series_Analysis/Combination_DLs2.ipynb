{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3c8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "np.random.seed(1265)\n",
    "from functools import reduce\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, MultiPolygon, Polygon\n",
    "from shapely.ops import unary_union\n",
    "import os\n",
    "\n",
    "###Machine Learning\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "##Supervised Learning\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "##Deep learning session\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005174fe",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c99cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_brackets_columns = ['resoFacts.patioAndPorchFeatures', 'resoFacts.waterSource', 'resoFacts.exteriorFeatures',\n",
    "                           'resoFacts.interiorFeatures', 'resoFacts.communityFeatures', 'resoFacts.constructionMaterials',\n",
    "                           'resoFacts.foundationDetails', 'resoFacts.utilities', 'resoFacts.appliances', \n",
    "                           'resoFacts.flooring', 'resoFacts.parkingFeatures',\n",
    "                           'resoFacts.lotFeatures', 'resoFacts.fireplaceFeatures', 'resoFacts.laundryFeatures', \n",
    "                           'resoFacts.propertySubType', 'resoFacts.securityFeatures', \n",
    "                           'resoFacts.cooling', 'resoFacts.windowFeatures', 'resoFacts.heating', 'resoFacts.sewer', \n",
    "                           'resoFacts.poolFeatures']\n",
    "\n",
    "string_comma_columns = ['resoFacts.architecturalStyle', \n",
    "                        'resoFacts.fencing', 'resoFacts.roofType']\n",
    "\n",
    "t = string_brackets_columns + string_comma_columns\n",
    "Selected_features = list(set(t) - set(['resoFacts.utilities', 'resoFacts.propertySubType']))\n",
    "\n",
    "Year_list2022 = ['2022']\n",
    "Month_list2022 = ['July', 'August', 'September', 'October', 'November', 'December']\n",
    "Year_list2023 = ['2023']\n",
    "Month_list2023 = ['January', 'February', 'March']\n",
    "\n",
    "##This is a dictionary that stores the original data everymonth\n",
    "original_data = dict()\n",
    "\n",
    "##This is a dictionary that store the datasets for every month\n",
    "monthly_data_dict1 = dict()\n",
    "\n",
    "##This is a dictionary that store datasets to run analysis\n",
    "monthly_data_dict2 = dict()\n",
    "path_abs = \"C:\\\\Users\\\\Khoatruong\\\\DATA365\\\\House Capstone Project\\\\Data cleaning\\\\Houses_categorical_property\\\\\"\n",
    "\n",
    "##Remove zipcode, city, county, SchoolDistrict since longitude and latitude will do the part\n",
    "\n",
    "def read_house_data(Monthlist, Yearlist, original_data, monthly_data_dict1, monthly_data_dict2):\n",
    "    for Year in Yearlist:\n",
    "        for Month in Monthlist:\n",
    "            main_df = pd.read_csv(\"C:\\\\Users\\\\Khoatruong\\\\DATA365\\\\House Capstone Project\\\\Data cleaning\\\\Clean_data_House_properties\\\\\" + Month + '_' + Year + '\\\\houses_properties_' + Month + '.csv')\n",
    "            cols = main_df.columns.tolist()\n",
    "\n",
    "            ##Rename some columns\n",
    "            for c in cols:\n",
    "                if 'resoFacts.' in c:\n",
    "                    feature = c.split('.')[1]\n",
    "                    main_df[feature] = main_df[c]\n",
    "                    main_df.drop(labels = [c], axis = 1, inplace = True)\n",
    "\n",
    "            ##Drop unimportant features \n",
    "            main_df.drop(labels = ['streetAddress', 'countyId', 'hasCooling', 'hasHeating'], axis = 1, inplace = True)\n",
    "            main_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "            ##Join the categorical dataframes\n",
    "            for category in Selected_features:\n",
    "                ft = category.split('.')[1]\n",
    "                name = 'houses' + '_' + ft + '.csv'\n",
    "                df_cat = pd.read_csv(path_abs + Month + '_' + Year + '\\\\' + name)\n",
    "                main_df = pd.merge(main_df, df_cat, how = 'left', on = 'zpid')\n",
    "\n",
    "            string_list = ['city', 'county', 'SchoolDistrict', 'levels']\n",
    "            for string in string_list:\n",
    "                main_df[string] = main_df[string].str.lower()\n",
    "            original_data[Month + '_' + Year] = main_df\n",
    "\n",
    "            ##Need the zpid (zillow id) to keep track of the data\n",
    "            #main_df.drop(labels = ['zpid'], axis = 1, inplace = True)\n",
    "            monthly_data_dict1[Month + '_' + Year] = main_df\n",
    "\n",
    "            remove_features = ['zipcode', 'city', 'SchoolDistrict', 'annualHomeownersInsurance']\n",
    "            main_df2 = main_df.copy()\n",
    "            main_df2.drop(labels = remove_features, axis = 1, inplace = True)\n",
    "            monthly_data_dict2[Month + '_' + Year] = main_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9deb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_house_data(Month_list2022, Year_list2022, original_data, monthly_data_dict1, monthly_data_dict2)\n",
    "read_house_data(Month_list2023, Year_list2023, original_data, monthly_data_dict1, monthly_data_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2b4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Month, df in monthly_data_dict1.items():\n",
    "    monthly_data_dict1[Month]['zipcode'] = monthly_data_dict1[Month]['zipcode'].astype('int64')\n",
    "\n",
    "for Month, df in monthly_data_dict1.items():\n",
    "    monthly_data_dict1[Month]['price/livingsqft'] = monthly_data_dict1[Month]['price'] / monthly_data_dict1[Month]['livingAreaValue']\n",
    "    monthly_data_dict1[Month]['price/lotsqft'] = monthly_data_dict1[Month]['price'] / monthly_data_dict1[Month]['lotArea']\n",
    "    monthly_data_dict1[Month]['liv/lot_ratio'] = monthly_data_dict1[Month]['livingAreaValue'] / monthly_data_dict1[Month]['lotArea']\n",
    "    monthly_data_dict1[Month]['living_price'] = df.apply(lambda row: row['price'] if row['liv/lot_ratio'] >= 1 else row['liv/lot_ratio']*row['price'], axis=1)\n",
    "    levels_df = pd.get_dummies(monthly_data_dict1[Month]['levels'], prefix = 'levels')\n",
    "    df = pd.concat([df.copy(), levels_df], axis=1)\n",
    "    df = df.copy().drop('levels', axis = 1)\n",
    "    ###Looking at a more dense location\n",
    "    df = df.copy().drop(df[(df['lotArea'] == 0) | (df['lotArea'] > 100000) | (df['price/lotsqft'] > 1000) \n",
    "                           | (df['liv/lot_ratio'] > 2)].index)\n",
    "    df = df.reset_index(drop = True)\n",
    "    monthly_data_dict1[Month] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d64110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Need to categorize levels\n",
    "True_False_features = ['isSeniorCommunity', 'hasAssociation', 'hasPrivatePool', 'hasGarage',\n",
    "                       'hasAttachedGarage', 'hasCarport', 'hasSpa', 'hasFireplace', 'isNewConstruction']\n",
    "\n",
    "Numerical_features = ['monthlyHoaFee', 'liv/lot_ratio', 'bedrooms', 'carportSpaces', 'garageSpaces', \n",
    "                      'coveredSpaces', 'parking', 'bathroomsHalf', 'bathroomsFull', 'fireplaces']\n",
    "\n",
    "##levels, laundry features, flooring features, construction features, exterior features, interior features, appliances,\n",
    "##foundations, lotFeatures, securityFeatures, sewer of the house.\n",
    "\n",
    "Categorical_features = ['levels_one', 'levels_one and one half', 'levels_two', 'levels_three or more',\n",
    "                        'levels_multi/split', 'laundryFeatures_none', 'laundryFeatures_electricdryerhookup',\n",
    "                        'laundryFeatures_fullsizew/darea', 'laundryFeatures_washerhookup', 'laundryFeatures_utilityroom',\n",
    "                        'laundryFeatures_other', 'flooring_carpet', 'flooring_laminate', 'flooring_vinyl',\n",
    "                        'flooring_ceramictile', 'flooring_hardwood', 'flooring_other', 'flooring_luxuryvinylplank',\n",
    "                        'flooring_tile', 'flooring_wood', 'constructionMaterials_siding', 'constructionMaterials_wood',\n",
    "                        'constructionMaterials_brick', 'constructionMaterials_other', 'constructionMaterials_frame',\n",
    "                        'constructionMaterials_fibercement', 'constructionMaterials_rock/stone', 'exteriorFeatures_coveredpatio/porch',\n",
    "                        'exteriorFeatures_storage', 'exteriorFeatures_other', 'exteriorFeatures_raingutters',\n",
    "                        'exteriorFeatures_lighting', 'exteriorFeatures_privateyard', 'interiorFeatures_granitecounters',\n",
    "                        'interiorFeatures_highspeedinternetavailable', 'interiorFeatures_other', 'interiorFeatures_cabletvavailable',\n",
    "                        'interiorFeatures_eat-inkitchen', 'interiorFeatures_pantry', 'interiorFeatures_openfloorplan',\n",
    "                        'interiorFeatures_kitchenisland', 'interiorFeatures_vaultedceiling(s)', \n",
    "                        'interiorFeatures_walk-incloset(s)', 'interiorFeatures_built-infeatures', 'interiorFeatures_decorativelighting',\n",
    "                        'interiorFeatures_smarthomesystem', 'interiorFeatures_doublevanity', 'interiorFeatures_flatscreenwiring',\n",
    "                        'interiorFeatures_chandelier', 'interiorFeatures_soundsystemwiring', 'interiorFeatures_wetbar',\n",
    "                        'appliances_electricrange', 'appliances_refrigerator', 'appliances_gasrange', 'appliances_dishwasher',\n",
    "                        'appliances_gasoven', 'appliances_gaswaterheater', 'appliances_electricoven', 'appliances_microwave',\n",
    "                        'appliances_electriccooktop', 'appliances_electricwaterheater', 'appliances_ventedexhaustfan',\n",
    "                        'appliances_disposal', 'appliances_plumbedforgasinkitchen', 'appliances_tanklesswaterheater',\n",
    "                        'appliances_gascooktop', 'appliances_doubleoven', 'appliances_convectionoven', 'appliances_built-ingasrange', \n",
    "                        'appliances_other', 'foundationDetails_pillar/post/pier', 'foundationDetails_slab',\n",
    "                        'foundationDetails_other', 'lotFeatures_lrg.backyardgrass', 'lotFeatures_acreage',\n",
    "                        'lotFeatures_cornerlot', 'lotFeatures_fewtrees', 'lotFeatures_none', 'lotFeatures_interiorlot',\n",
    "                        'lotFeatures_subdivided', 'lotFeatures_cul-de-sac', 'lotFeatures_landscaped',\n",
    "                        'lotFeatures_sprinklersystem', 'lotFeatures_other', 'lotFeatures_manytrees',\n",
    "                        'securityFeatures_none', 'securityFeatures_smokedetector(s)', 'securityFeatures_carbonmonoxidedetector(s)',\n",
    "                        'securityFeatures_firealarm', 'securityFeatures_securitysystem',\n",
    "                        'securityFeatures_securitysystemowned', 'securityFeatures_burglar', 'securityFeatures_prewired',\n",
    "                        'securityFeatures_other', 'sewer_citysewer', 'sewer_aerobicseptic', 'sewer_septic',\n",
    "                        'sewer_other']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10492b76",
   "metadata": {},
   "source": [
    "## Redesign the location data\n",
    "redesign the location data due to new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4542d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_cols = ['zpid', 'latitude', 'longitude', 'county', 'SchoolDistrict', 'zipcode', \n",
    "                 'liv/lot_ratio', 'price/lotsqft', 'price/livingsqft']\n",
    "monthly_location2 = dict()\n",
    "for Month, df in monthly_data_dict1.items():\n",
    "    ##Store the location data into this dictionary\n",
    "    df_location = df.copy()[location_cols]\n",
    "    monthly_location2[Month] = df_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337219e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_df2 = gpd.read_file('ALL_US_county/tl_rd22_us_county.shp')\n",
    "shape_df2['NAME'] = shape_df2['NAME'].str.lower()\n",
    "shape_df2['INTPTLAT'] = shape_df2['INTPTLAT'].astype('float64')\n",
    "shape_df2['INTPTLON'] = shape_df2['INTPTLON'].astype('float64')\n",
    "\n",
    "shape_df3 = gpd.read_file('Texas_SchoolDistrict/tl_rd22_48_unsd.shp')\n",
    "shape_df3['NAME'] = shape_df3['NAME'].str.lower().replace('independent school district', 'isd', regex = True)\n",
    "shape_df3['INTPTLAT'] = shape_df3['INTPTLAT'].astype('float64')\n",
    "shape_df3['INTPTLON'] = shape_df3['INTPTLON'].astype('float64')\n",
    "\n",
    "shape_df4 = gpd.read_file('ALL_US_zipcode/tl_rd22_us_zcta520.shp')\n",
    "shape_df4['ZCTA5CE20'] = shape_df4['ZCTA5CE20'].astype('int64')\n",
    "shape_df4['GEOID20'] = shape_df4['GEOID20'].astype('int64')\n",
    "shape_df4['INTPTLAT20'] = shape_df4['INTPTLAT20'].astype('float64')\n",
    "shape_df4['INTPTLON20'] = shape_df4['INTPTLON20'].astype('float64')\n",
    "shape_df4['INTPTLAT'] = shape_df4['INTPTLAT20']\n",
    "shape_df4['INTPTLON'] = shape_df4['INTPTLON20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027834f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Month, df in monthly_location2.items():\n",
    "    all_counties_list = np.sort(df['county'].unique())\n",
    "    counties_location_df = shape_df2.copy()\n",
    "    counties_location_df = counties_location_df[(counties_location_df['NAME'].isin(all_counties_list)) & \n",
    "                                                (counties_location_df['GEOID'].str.contains('48'))].reset_index(drop = True)\n",
    "    counties_location_df['county_lat'] = counties_location_df['INTPTLAT']\n",
    "    counties_location_df['county_long'] = counties_location_df['INTPTLON']\n",
    "    counties_location_df['county'] = counties_location_df['NAME']\n",
    "    \n",
    "    all_SD_list = np.sort(df['SchoolDistrict'].unique())\n",
    "    SD_location_df = shape_df3.copy()\n",
    "    SD_location_df = SD_location_df[SD_location_df['NAME'].isin(all_SD_list) &\n",
    "                                   (SD_location_df['INTPTLON'] >= -98.5) & \n",
    "                                   (SD_location_df['INTPTLON'] <= -95.8) &\n",
    "                                   (SD_location_df['INTPTLAT'] >= 32) &\n",
    "                                   (SD_location_df['INTPTLAT'] <= 33.70)].reset_index(drop = True)\n",
    "    SD_location_df['SD_lat'] = SD_location_df['INTPTLAT']\n",
    "    SD_location_df['SD_long'] = SD_location_df['INTPTLON']\n",
    "    SD_location_df['SchoolDistrict'] = SD_location_df['NAME']\n",
    "    \n",
    "    all_zipcode_list = np.sort(df['zipcode'].unique())\n",
    "    zipcode_location_df = shape_df4.copy()\n",
    "    zipcode_location_df = zipcode_location_df[zipcode_location_df['ZCTA5CE20'].isin(all_zipcode_list) &\n",
    "                                             (zipcode_location_df['INTPTLON20'] >= -98.5) & \n",
    "                                             (zipcode_location_df['INTPTLON20'] <= -95.8) &\n",
    "                                             (zipcode_location_df['INTPTLAT20'] >= 32) &\n",
    "                                             (zipcode_location_df['INTPTLAT20'] <= 33.70)].reset_index(drop = True)\n",
    "    zipcode_location_df['zipcode_lat'] = zipcode_location_df['INTPTLAT']\n",
    "    zipcode_location_df['zipcode_long'] = zipcode_location_df['INTPTLON']\n",
    "    zipcode_location_df['zipcode'] = zipcode_location_df['ZCTA5CE20']\n",
    "    \n",
    "    merge_df = pd.merge(df, counties_location_df.copy()[['county', 'county_lat', 'county_long']], on=['county'], how='left')\n",
    "    merge_df = pd.merge(merge_df, SD_location_df.copy()[['SchoolDistrict', 'SD_lat', 'SD_long']], on=['SchoolDistrict'], how='left')\n",
    "    merge_df = pd.merge(merge_df, zipcode_location_df.copy()[['zipcode', 'zipcode_lat', 'zipcode_long']], on=['zipcode'], how='left')\n",
    "    \n",
    "    new_df = merge_df.copy()[['zpid', 'latitude', 'longitude', 'county_lat', \n",
    "                              'county_long', 'SD_lat', 'SD_long', 'zipcode_lat', 'zipcode_long', \n",
    "                              'price/livingsqft', 'price/lotsqft', 'liv/lot_ratio']]\n",
    "    \n",
    "    ###Check for null coords, if they are null, fill them with the coordinates of the houses\n",
    "    new_df['SD_lat'].fillna(new_df['latitude'], inplace = True)\n",
    "    new_df['SD_long'].fillna(new_df['longitude'], inplace = True)\n",
    "    \n",
    "    new_df['zipcode_lat'].fillna(new_df['latitude'], inplace = True)\n",
    "    new_df['zipcode_long'].fillna(new_df['longitude'], inplace = True)\n",
    "    \n",
    "    new_df['county_lat'].fillna(new_df['latitude'], inplace = True)\n",
    "    new_df['county_long'].fillna(new_df['longitude'], inplace = True)\n",
    "    Monthly_path = 'Location_data3/' + Month\n",
    "    if not os.path.exists(Monthly_path):\n",
    "        os.makedirs(Monthly_path)\n",
    "    \n",
    "    new_df.to_csv(Monthly_path + '/' + Month + '_houses_location.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ecd14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Location df contains more samples since the rule lotArea < 100000 is not applied here\n",
    "Month_list = ['July_2022', 'August_2022', 'September_2022', 'October_2022', 'November_2022',\n",
    "              'December_2022', 'January_2023', 'February_2023', 'March_2023']\n",
    "monthly_location_dict1 = dict()\n",
    "\n",
    "for month in Month_list:\n",
    "    ###Read in all the datasets\n",
    "    Month_path = 'Location_data3/' + month + '/' + month + '_houses_location.csv'\n",
    "    df_location = pd.read_csv(Month_path)\n",
    "    monthly_location_dict1[month] = df_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488898fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, True_False_features, Numerical_features, Categorical_features):\n",
    "    df_transformed = df.copy()\n",
    "    for ft in True_False_features:\n",
    "        df_transformed.loc[df_transformed[ft] == True, ft] = 1\n",
    "        df_transformed.loc[df_transformed[ft] == False, ft] = 0\n",
    "        df_transformed[ft] = df_transformed[ft].astype(int)\n",
    "    return df_transformed[True_False_features + Numerical_features + Categorical_features + ['living_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4703313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_combination_data(splits, scaler, original_df, df_model1, df_model2, Numerical_features):\n",
    "    data1 = df_model1.to_numpy()\n",
    "    data2 = df_model2.to_numpy()\n",
    "    cv = KFold(n_splits = splits, shuffle = True, random_state = 0)\n",
    "    cv.split(original_df)\n",
    "\n",
    "    train_set_dict1 = dict()\n",
    "    train_target_dict1 = dict()\n",
    "    scaled_train_set1 = dict()\n",
    "    scaled_train_target1 = dict()\n",
    "\n",
    "    test_set_dict1 = dict()\n",
    "    test_target_dict1 = dict()\n",
    "    scaled_test_set1 = dict()\n",
    "    scaled_test_target1 = dict()\n",
    "    \n",
    "    train_set_dict2 = dict()\n",
    "    train_target_dict2 = dict()\n",
    "    scaled_train_set2 = dict()\n",
    "    scaled_train_target2 = dict()\n",
    "\n",
    "    test_set_dict2 = dict()\n",
    "    test_target_dict2 = dict()\n",
    "    scaled_test_set2 = dict()\n",
    "    scaled_test_target2 = dict()\n",
    "\n",
    "    ###Create 2 different unique dictionary to track the prediction of real price\n",
    "    original_train = dict()\n",
    "    original_test = dict()\n",
    "    \n",
    "    ###Store K folds data into dictionary\n",
    "    for i, (train_index, test_index) in enumerate(cv.split(original_df)):\n",
    "        ###1 means location data\n",
    "        train_set1 = df_model1.iloc[train_index].iloc[:, :-1]\n",
    "        train_target1 = df_model1.iloc[train_index].iloc[:, -1]\n",
    "        train_set_dict1['Fold ' + str(i)] = train_set1.copy()\n",
    "        train_target_dict1['Fold ' + str(i)] = train_target1.copy()\n",
    "\n",
    "        test_set1 = df_model1.iloc[test_index].iloc[:, :-1]\n",
    "        test_target1 = df_model1.iloc[test_index].iloc[:, -1]\n",
    "        test_set_dict1['Fold ' + str(i)] = test_set1.copy()\n",
    "        test_target_dict1['Fold ' + str(i)] = test_target1.copy()\n",
    "        \n",
    "        ###2 means properties data\n",
    "        train_set2 = df_model2.iloc[train_index].iloc[:, :-1]\n",
    "        train_target2 = df_model2.iloc[train_index].iloc[:, -1]\n",
    "        train_set_dict2['Fold ' + str(i)] = train_set2.copy()\n",
    "        train_target_dict2['Fold ' + str(i)] = train_target2.copy()\n",
    "\n",
    "        test_set2 = df_model2.iloc[test_index].iloc[:, :-1]\n",
    "        test_target2 = df_model2.iloc[test_index].iloc[:, -1]\n",
    "        test_set_dict2['Fold ' + str(i)] = test_set2.copy()\n",
    "        test_target_dict2['Fold ' + str(i)] = test_target2.copy()\n",
    "        \n",
    "        ###Keeping the liv/lot_ratio, lot_area, living area\n",
    "        original_train['Fold ' + str(i)] = original_df.iloc[train_index][['zpid', 'livingAreaValue', 'lotArea', 'liv/lot_ratio']]\n",
    "        original_test['Fold ' + str(i)] = original_df.iloc[test_index][['zpid', 'livingAreaValue', 'lotArea', 'liv/lot_ratio']]\n",
    "        \n",
    "        ###for location data\n",
    "        the_scaler1 = scaler\n",
    "        scaled_train_set1['Fold ' + str(i)] = the_scaler1.fit_transform(train_set1)\n",
    "        scaled_train_target1['Fold ' + str(i)] = np.log(train_target_dict1['Fold ' + str(i)]).to_numpy().reshape(-1, 1)\n",
    "        scaled_test_set1['Fold ' + str(i)] = the_scaler1.transform(test_set1)\n",
    "        scaled_test_target1['Fold ' + str(i)] = np.log(test_target_dict1['Fold ' + str(i)]).to_numpy().reshape(-1, 1)\n",
    "        \n",
    "        ###for properties data\n",
    "        the_scaler2 = scaler\n",
    "        scaled_train2 = train_set2.copy()\n",
    "        scaled_test2 = test_set2.copy()\n",
    "        num_transformer = ColumnTransformer(transformers=[('num', MinMaxScaler(), Numerical_features)])\n",
    "        scaled_train2[Numerical_features] = num_transformer.fit_transform(train_set2.copy()[Numerical_features])\n",
    "        scaled_test2[Numerical_features] = num_transformer.transform(test_set2.copy()[Numerical_features])\n",
    "        scaled_train_set2['Fold ' + str(i)] = scaled_train2\n",
    "        scaled_train_target2['Fold ' + str(i)] = np.log(train_target_dict2['Fold ' + str(i)]).to_numpy().reshape(-1, 1)\n",
    "        scaled_test_set2['Fold ' + str(i)] = scaled_test2\n",
    "        scaled_test_target2['Fold ' + str(i)] = np.log(test_target_dict2['Fold ' + str(i)]).to_numpy().reshape(-1, 1)\n",
    "        \n",
    "    return (train_set_dict1, train_target_dict1, scaled_train_set1, scaled_train_target1,\n",
    "            test_set_dict1, test_target_dict1, scaled_test_set1, scaled_test_target1,\n",
    "            train_set_dict2, train_target_dict2, scaled_train_set2, scaled_train_target2,\n",
    "            test_set_dict2, test_target_dict2, scaled_test_set2, scaled_test_target2, original_train, original_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a6bbf",
   "metadata": {},
   "source": [
    "## Try this on February dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1caaf71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feb2023 = monthly_data_dict1['February_2023']\n",
    "original_df = df_feb2023.copy()\n",
    "df_model1 = monthly_location_dict1['February_2023'].copy()[['latitude', 'longitude', 'county_lat', 'county_long', \n",
    "                                                            'liv/lot_ratio', 'SD_lat', 'SD_long', 'zipcode_lat', \n",
    "                                                            'zipcode_long', 'price/lotsqft']]\n",
    "df_model2 = transform_data(df_feb2023.copy(), True_False_features, Numerical_features, Categorical_features)\n",
    "\n",
    "splits = 5\n",
    "scaler = MinMaxScaler()\n",
    "all_dicts = prep_combination_data(splits, scaler, original_df, df_model1, df_model2, Numerical_features)\n",
    "train_set_dict1 = all_dicts[0]\n",
    "train_target_dict1 = all_dicts[1]\n",
    "scaled_train_set1 = all_dicts[2]\n",
    "scaled_train_target1 = all_dicts[3]\n",
    "test_set_dict1 = all_dicts[4]\n",
    "test_target_dict1 = all_dicts[5]\n",
    "scaled_test_set1 = all_dicts[6]\n",
    "scaled_test_target1 = all_dicts[7]\n",
    "\n",
    "train_set_dict2 = all_dicts[8]\n",
    "train_target_dict2 = all_dicts[9]\n",
    "scaled_train_set2 = all_dicts[10]\n",
    "scaled_train_target2 = all_dicts[11]\n",
    "test_set_dict2 = all_dicts[12]\n",
    "test_target_dict2 = all_dicts[13]\n",
    "scaled_test_set2 = all_dicts[14]\n",
    "scaled_test_target2 = all_dicts[15]\n",
    "\n",
    "original_train = all_dicts[16]\n",
    "original_test = all_dicts[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d6199",
   "metadata": {},
   "source": [
    "#### Location prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c55e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_location_generator(input_shape):\n",
    "    T = input_shape\n",
    "    i = Input(shape = [T,])\n",
    "    x = Dense(2000)(i)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(inputs = i, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cda7258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test R-squared score: 0.8031\n",
      "Fold 1 Test Adjusted R-squared score: 0.8022\n",
      "Fold 1 RMSE: 119494.2698\n",
      "Fold 1 MAE: 70722.5553\n",
      "\n",
      "Fold 2 Test R-squared score: 0.8228\n",
      "Fold 2 Test Adjusted R-squared score: 0.8221\n",
      "Fold 2 RMSE: 112191.4445\n",
      "Fold 2 MAE: 66855.8954\n",
      "\n",
      "Fold 3 Test R-squared score: 0.8397\n",
      "Fold 3 Test Adjusted R-squared score: 0.839\n",
      "Fold 3 RMSE: 109303.4241\n",
      "Fold 3 MAE: 64832.9568\n",
      "\n",
      "Fold 4 Test R-squared score: 0.8339\n",
      "Fold 4 Test Adjusted R-squared score: 0.8332\n",
      "Fold 4 RMSE: 109745.4366\n",
      "Fold 4 MAE: 65940.5357\n",
      "\n",
      "Fold 5 Test R-squared score: 0.8028\n",
      "Fold 5 Test Adjusted R-squared score: 0.802\n",
      "Fold 5 RMSE: 123023.6377\n",
      "Fold 5 MAE: 71196.3075\n",
      "\n",
      "The average Train R-squared :  0.8194\n",
      "The average Test R-squared :  0.8205\n",
      "The average Test adjusted R-squared:  0.8197\n",
      "The average deviation from actual value (RMSE):  114751.6425\n",
      "The average deviation from actual value (MAE):  67909.6501\n",
      "Difference between Train vs. Test R-squared:  -0.11 %\n"
     ]
    }
   ],
   "source": [
    "Test_R2_list = list()\n",
    "Test_adjusted_R2_list = list()\n",
    "Train_R2_list = list()\n",
    "rmse_list = list()\n",
    "mae_list = list()\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "input_shape = train_set_dict1['Fold 0'].shape[1]\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 990\n",
    "decay_rate = 0.85\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps, \n",
    "                                                             decay_rate, staircase=True)\n",
    "Adam = tf.keras.optimizers.Adam(learning_rate = lr_schedule)\n",
    "model1 = ann_location_generator(input_shape)\n",
    "model1.compile(loss = 'mean_squared_error', optimizer = Adam, metrics = ['mse'])\n",
    "\n",
    "for i in range(5):\n",
    "    train_set1 = scaled_train_set1['Fold ' + str(i)]\n",
    "    train_target1 = scaled_train_target1['Fold ' + str(i)]\n",
    "    test_set1 = scaled_test_set1['Fold ' + str(i)]\n",
    "    test_target1 = scaled_test_target1['Fold ' + str(i)]\n",
    "\n",
    "    check_point = ModelCheckpoint('Location_ANN_vars/model1_adam_ann_' + 'Fold ' + str(i) + '.h5', \n",
    "                                   monitor = 'val_mse', save_best_only = True)\n",
    "    model1.fit(train_set1, train_target1, epochs = 80, validation_data = (test_set1, test_target1), \n",
    "               batch_size = 32, callbacks = [check_point], verbose = 0)\n",
    "    model_allvars = tf.keras.models.load_model('Location_ANN_vars/model1_adam_ann_' + 'Fold ' + str(i) + '.h5')\n",
    "    train_observed = train_target_dict1['Fold ' + str(i)].to_numpy().reshape(-1, 1)\n",
    "    train_predicted = np.exp(model_allvars.predict(train_set1))\n",
    "    original_train['Fold ' + str(i)]['predicted_price/lotsqft'] = train_predicted\n",
    "    original_train['Fold ' + str(i)]['actual_price/lotsqft'] = train_observed\n",
    "    original_train['Fold ' + str(i)]['actual_price'] =  original_train['Fold ' + str(i)]['lotArea'] * original_train['Fold ' + str(i)]['actual_price/lotsqft']\n",
    "    original_train['Fold ' + str(i)]['predicted_price1'] = original_train['Fold ' + str(i)]['lotArea'] * original_train['Fold ' + str(i)]['predicted_price/lotsqft']\n",
    "    train_r_squared = r2_score(original_train['Fold ' + str(i)]['actual_price'], original_train['Fold ' + str(i)]['predicted_price1'])\n",
    "    \n",
    "    ###For the test set\n",
    "    test_observed = test_target_dict1['Fold ' + str(i)].to_numpy().reshape(-1, 1)\n",
    "    test_predicted = np.exp(model_allvars.predict(test_set1))\n",
    "    original_test['Fold ' + str(i)]['predicted_price/lotsqft'] = test_predicted\n",
    "    original_test['Fold ' + str(i)]['actual_price/lotsqft'] = test_observed\n",
    "    original_test['Fold ' + str(i)]['actual_price'] =  original_test['Fold ' + str(i)]['lotArea'] * original_test['Fold ' + str(i)]['actual_price/lotsqft']\n",
    "    original_test['Fold ' + str(i)]['predicted_price1'] = original_test['Fold ' + str(i)]['lotArea'] * original_test['Fold ' + str(i)]['predicted_price/lotsqft']    \n",
    "    test_r_squared = r2_score(original_test['Fold ' + str(i)]['actual_price'], original_test['Fold ' + str(i)]['predicted_price1'])\n",
    "    \n",
    "    r2 = test_r_squared\n",
    "    n = test_observed.shape[0]\n",
    "    p = train_set1.shape[1]\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "    mse = mean_squared_error(original_test['Fold ' + str(i)]['actual_price'], original_test['Fold ' + str(i)]['predicted_price1'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(original_test['Fold ' + str(i)]['actual_price'], original_test['Fold ' + str(i)]['predicted_price1'])\n",
    "\n",
    "    Test_R2_list.append(r2)\n",
    "    Test_adjusted_R2_list.append(adjusted_r2)\n",
    "    Train_R2_list.append(train_r_squared)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    \n",
    "    print(\"Fold \" + str(i + 1) + \" Test R-squared score:\", np.round(r2, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" Test Adjusted R-squared score:\", np.round(adjusted_r2, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" RMSE:\", np.round(rmse, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" MAE:\", np.round(mae, 4))\n",
    "    print()\n",
    "    \n",
    "dif = np.round(sum(Train_R2_list)/len(Train_R2_list), 4) - np.round(sum(Test_R2_list)/len(Test_R2_list), 4)\n",
    "dif = np.round(dif * 100, 2)\n",
    "print(\"The average Train R-squared : \", np.round(sum(Train_R2_list)/len(Train_R2_list), 4))\n",
    "print(\"The average Test R-squared : \", np.round(sum(Test_R2_list)/len(Test_R2_list), 4))\n",
    "print(\"The average Test adjusted R-squared: \", np.round(sum(Test_adjusted_R2_list)/len(Test_adjusted_R2_list), 4))\n",
    "print(\"The average deviation from actual value (RMSE): \", np.round(sum(rmse_list)/len(rmse_list), 4))\n",
    "print(\"The average deviation from actual value (MAE): \", np.round(sum(mae_list)/len(mae_list), 4))\n",
    "print(\"Difference between Train vs. Test R-squared: \", dif, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b85e5",
   "metadata": {},
   "source": [
    "#### Properties prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2907a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_properties_generator(input_shape):\n",
    "    T = input_shape\n",
    "    i = Input(shape = [T,])\n",
    "    x = Dense(80)(i)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(60)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(20)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(inputs = i, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "932d523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test R-squared score: 0.5652\n",
      "Fold 1 Test Adjusted R-squared score: 0.5395\n",
      "Fold 1 RMSE: 177571.4983\n",
      "Fold 1 MAE: 107376.6296\n",
      "\n",
      "Fold 2 Test R-squared score: 0.8183\n",
      "Fold 2 Test Adjusted R-squared score: 0.8075\n",
      "Fold 2 RMSE: 113634.0453\n",
      "Fold 2 MAE: 71772.0958\n",
      "\n",
      "Fold 3 Test R-squared score: 0.8674\n",
      "Fold 3 Test Adjusted R-squared score: 0.8595\n",
      "Fold 3 RMSE: 99417.2532\n",
      "Fold 3 MAE: 67334.0395\n",
      "\n",
      "Fold 4 Test R-squared score: 0.9124\n",
      "Fold 4 Test Adjusted R-squared score: 0.9072\n",
      "Fold 4 RMSE: 79704.8538\n",
      "Fold 4 MAE: 55698.3833\n",
      "\n",
      "Fold 5 Test R-squared score: 0.9249\n",
      "Fold 5 Test Adjusted R-squared score: 0.9205\n",
      "Fold 5 RMSE: 75904.1603\n",
      "Fold 5 MAE: 51268.9058\n",
      "\n",
      "The average Train R-squared :  0.8918\n",
      "The average Test R-squared :  0.8176\n",
      "The average Test adjusted R-squared:  0.8069\n",
      "The average deviation from actual value (RMSE):  109246.3622\n",
      "The average deviation from actual value (MAE):  70690.0108\n",
      "Difference between Train vs. Test R-squared:  7.42 %\n"
     ]
    }
   ],
   "source": [
    "Test_R2_list = list()\n",
    "Test_adjusted_R2_list = list()\n",
    "Train_R2_list = list()\n",
    "rmse_list = list()\n",
    "mae_list = list()\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "input_shape = train_set_dict2['Fold 0'].shape[1]\n",
    "model2 = ann_properties_generator(input_shape)\n",
    "model2.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "for i in range(5):\n",
    "    train_set2 = scaled_train_set2['Fold ' + str(i)]\n",
    "    train_target2 = scaled_train_target2['Fold ' + str(i)]\n",
    "    test_set2 = scaled_test_set2['Fold ' + str(i)]\n",
    "    test_target2 = scaled_test_target2['Fold ' + str(i)]\n",
    "\n",
    "    check_point = ModelCheckpoint('Properties_ANN_vars/model2_adam_ann_' + 'Fold ' + str(i) + '.h5', \n",
    "                                   monitor = 'val_mse', save_best_only = True)\n",
    "    model2.fit(train_set2, train_target2, epochs = 80, validation_data = (test_set2, test_target2), \n",
    "               batch_size = 32, callbacks = [check_point], verbose = 0)\n",
    "    model_allvars = tf.keras.models.load_model('Properties_ANN_vars/model2_adam_ann_' + 'Fold ' + str(i) + '.h5')\n",
    "    train_observed = train_target_dict2['Fold ' + str(i)].to_numpy().reshape(-1, 1)\n",
    "    train_predicted = np.exp(model_allvars.predict(train_set2))\n",
    "    \n",
    "    ###We have calculated the actual price already with lot * price/lot\n",
    "    original_train['Fold ' + str(i)]['actual_living_price'] = train_observed\n",
    "    original_train['Fold ' + str(i)]['predicted_living_price'] = train_predicted\n",
    "    original_train['Fold ' + str(i)]['lot/liv_ratio'] = original_train['Fold ' + str(i)]['liv/lot_ratio'].apply(lambda x: 1/x)\n",
    "    original_train['Fold ' + str(i)]['predicted_price2'] = original_train['Fold ' + str(i)].apply(lambda row: row['predicted_living_price'] if row['liv/lot_ratio'] >= 1 \n",
    "                                                                                                                                            else row['lot/liv_ratio'] * row['predicted_living_price'], axis=1)\n",
    "    train_r_squared = r2_score(original_train['Fold ' + str(i)]['actual_price'], original_train['Fold ' + str(i)]['predicted_price2'])\n",
    "    \n",
    "    ###For the test set\n",
    "    test_observed = test_target_dict2['Fold ' + str(i)].to_numpy().reshape(-1, 1)\n",
    "    test_predicted = np.exp(model_allvars.predict(test_set2))\n",
    "    original_test['Fold ' + str(i)]['actual_living_price'] = test_observed\n",
    "    original_test['Fold ' + str(i)]['predicted_living_price'] = test_predicted\n",
    "    original_test['Fold ' + str(i)]['lot/liv_ratio'] = original_test['Fold ' + str(i)]['liv/lot_ratio'].apply(lambda x: 1/x)\n",
    "    original_test['Fold ' + str(i)]['predicted_price2'] = original_test['Fold ' + str(i)].apply(lambda row: row['predicted_living_price'] if row['liv/lot_ratio'] >= 1 \n",
    "                                                                                                                                          else row['lot/liv_ratio'] * row['predicted_living_price'], axis=1)    \n",
    "    test_r_squared = r2_score(original_test['Fold ' + str(i)]['actual_price'], original_test['Fold ' + str(i)]['predicted_price2'])\n",
    "    \n",
    "    r2 = test_r_squared\n",
    "    n = test_observed.shape[0]\n",
    "    p = train_set2.shape[1]\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "    mse = mean_squared_error(original_test['Fold ' + str(i)]['actual_price'], original_test['Fold ' + str(i)]['predicted_price2'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(original_test['Fold ' + str(i)]['actual_price'], original_test['Fold ' + str(i)]['predicted_price2'])\n",
    "\n",
    "    Test_R2_list.append(r2)\n",
    "    Test_adjusted_R2_list.append(adjusted_r2)\n",
    "    Train_R2_list.append(train_r_squared)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    \n",
    "    print(\"Fold \" + str(i + 1) + \" Test R-squared score:\", np.round(r2, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" Test Adjusted R-squared score:\", np.round(adjusted_r2, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" RMSE:\", np.round(rmse, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" MAE:\", np.round(mae, 4))\n",
    "    print()\n",
    "    \n",
    "dif = np.round(sum(Train_R2_list)/len(Train_R2_list), 4) - np.round(sum(Test_R2_list)/len(Test_R2_list), 4)\n",
    "dif = np.round(dif * 100, 2)\n",
    "print(\"The average Train R-squared : \", np.round(sum(Train_R2_list)/len(Train_R2_list), 4))\n",
    "print(\"The average Test R-squared : \", np.round(sum(Test_R2_list)/len(Test_R2_list), 4))\n",
    "print(\"The average Test adjusted R-squared: \", np.round(sum(Test_adjusted_R2_list)/len(Test_adjusted_R2_list), 4))\n",
    "print(\"The average deviation from actual value (RMSE): \", np.round(sum(rmse_list)/len(rmse_list), 4))\n",
    "print(\"The average deviation from actual value (MAE): \", np.round(sum(mae_list)/len(mae_list), 4))\n",
    "print(\"Difference between Train vs. Test R-squared: \", dif, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e17fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "for i in range(n_folds):\n",
    "    path_train = 'Cross_val_df/Train/'\n",
    "    path_test = 'Cross_val_df/Test/'\n",
    "    original_train['Fold ' + str(i)].to_csv(path_train + 'original_train_result_Fold '+ str(i) + '.csv', index = True)\n",
    "    original_test['Fold ' + str(i)].to_csv(path_test + 'original_test_result_Fold ' + str(i) + '.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6933168",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = dict()\n",
    "original_test = dict()\n",
    "\n",
    "for i in range(5):\n",
    "    original_train['Fold ' + str(i)] = pd.read_csv('Cross_val_df/Train/original_train_result_Fold '+ str(i) + '.csv', index_col = 0)\n",
    "    original_test['Fold ' + str(i)] = pd.read_csv('Cross_val_df/Test/original_test_result_Fold '+ str(i) + '.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33fdf7d",
   "metadata": {},
   "source": [
    "##### Price prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b8544a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_ml(model, original_train, original_test, verbose = 0):\n",
    "    Test_R2_list = list()\n",
    "    Test_adjusted_R2_list = list()\n",
    "    Train_R2_list = list()\n",
    "    rmse_list = list()\n",
    "    mae_list = list()\n",
    "    \n",
    "    columns = ['livingAreaValue', 'lotArea', 'liv/lot_ratio', 'predicted_price/lotsqft', 'predicted_living_price',\n",
    "               'predicted_price1', 'predicted_price2']\n",
    "    for i in range(5):\n",
    "        train_set = original_train['Fold ' + str(i)].copy()[columns].to_numpy()\n",
    "        train_target = original_train['Fold ' + str(i)].copy()['actual_price'].to_numpy()\n",
    "        test_set = original_test['Fold ' + str(i)].copy()[columns].to_numpy()\n",
    "        test_target = original_test['Fold ' + str(i)].copy()['actual_price'].to_numpy()\n",
    "        model.fit(train_set, train_target)\n",
    "        \n",
    "        train_predicted = model.predict(train_set)\n",
    "        original_train['Fold ' + str(i)]['predicted_price_comb'] = train_predicted\n",
    "        train_r_squared = model.score(train_set, train_target)\n",
    "        \n",
    "        test_observed = test_target\n",
    "        test_predicted = model.predict(test_set)\n",
    "        original_test['Fold ' + str(i)]['predicted_price_comb'] = test_predicted\n",
    "        r2 = r2_score(test_observed, test_predicted)\n",
    "        n = test_observed.shape[0]\n",
    "        p = train_set.shape[1]\n",
    "        adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "        mse = mean_squared_error(test_observed, test_predicted)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(test_observed, test_predicted)\n",
    "\n",
    "        Test_R2_list.append(r2)\n",
    "        Test_adjusted_R2_list.append(adjusted_r2)\n",
    "        Train_R2_list.append(train_r_squared)\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        \n",
    "        if verbose == 1:\n",
    "            print(\"Fold \" + str(i + 1) + \" Test R-squared score:\", np.round(r2, 4))\n",
    "            print(\"Fold \" + str(i + 1) + \" Test Adjusted R-squared score:\", np.round(adjusted_r2, 4))\n",
    "            print(\"Fold \" + str(i + 1) + \" RMSE:\", np.round(rmse, 4))\n",
    "            print(\"Fold \" + str(i + 1) + \" MAE:\", np.round(mae, 4))\n",
    "            print()\n",
    "    dif = np.round(sum(Train_R2_list)/len(Train_R2_list), 4) - np.round(sum(Test_R2_list)/len(Test_R2_list), 4)\n",
    "    dif = np.round(dif * 100, 2)\n",
    "    if verbose == 1:\n",
    "        print(\"The average Train R-squared : \", np.round(sum(Train_R2_list)/len(Train_R2_list), 4))\n",
    "        print(\"The average Test R-squared : \", np.round(sum(Test_R2_list)/len(Test_R2_list), 4))\n",
    "        print(\"The average Test adjusted R-squared: \", np.round(sum(Test_adjusted_R2_list)/len(Test_adjusted_R2_list), 4))\n",
    "        print(\"The average deviation from actual value (RMSE): \", np.round(sum(rmse_list)/len(rmse_list), 4))\n",
    "        print(\"The average deviation from actual value (MAE): \", np.round(sum(mae_list)/len(mae_list), 4))\n",
    "        print(\"Difference between Train vs. Test R-squared: \", dif, \"%\")\n",
    "    avg_Train_R2 = np.round(sum(Train_R2_list)/len(Train_R2_list), 4)\n",
    "    avg_Test_R2 = np.round(sum(Test_R2_list)/len(Test_R2_list), 4)\n",
    "    avg_Test_adjusted_R2 = np.round(sum(Test_adjusted_R2_list)/len(Test_adjusted_R2_list), 4)\n",
    "    avg_Test_RMSE = np.round(sum(rmse_list)/len(rmse_list), 4)\n",
    "    avg_Test_MAE = np.round(sum(mae_list)/len(mae_list), 4)\n",
    "    return (avg_Train_R2, avg_Test_R2, avg_Test_adjusted_R2, avg_Test_RMSE, avg_Test_MAE, dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "441dad19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test R-squared score: 0.7719\n",
      "Fold 1 Test Adjusted R-squared score: 0.7712\n",
      "Fold 1 RMSE: 128603.0007\n",
      "Fold 1 MAE: 74207.3023\n",
      "\n",
      "Fold 2 Test R-squared score: 0.9102\n",
      "Fold 2 Test Adjusted R-squared score: 0.9099\n",
      "Fold 2 RMSE: 79865.955\n",
      "Fold 2 MAE: 50231.9413\n",
      "\n",
      "Fold 3 Test R-squared score: 0.933\n",
      "Fold 3 Test Adjusted R-squared score: 0.9328\n",
      "Fold 3 RMSE: 70643.9851\n",
      "Fold 3 MAE: 45052.2246\n",
      "\n",
      "Fold 4 Test R-squared score: 0.9572\n",
      "Fold 4 Test Adjusted R-squared score: 0.9571\n",
      "Fold 4 RMSE: 55698.3013\n",
      "Fold 4 MAE: 36052.894\n",
      "\n",
      "Fold 5 Test R-squared score: 0.9623\n",
      "Fold 5 Test Adjusted R-squared score: 0.9622\n",
      "Fold 5 RMSE: 53766.8087\n",
      "Fold 5 MAE: 34021.8296\n",
      "\n",
      "The average Train R-squared :  0.9706\n",
      "The average Test R-squared :  0.9069\n",
      "The average Test adjusted R-squared:  0.9066\n",
      "The average deviation from actual value (RMSE):  77715.6102\n",
      "The average deviation from actual value (MAE):  47913.2384\n",
      "Difference between Train vs. Test R-squared:  6.37 %\n"
     ]
    }
   ],
   "source": [
    "hgbr = HistGradientBoostingRegressor()\n",
    "_ = price_ml(hgbr, original_train, original_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba379d",
   "metadata": {},
   "source": [
    "### Tuning the hgbr model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f2ba1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test R-squared score: 0.7868\n",
      "Fold 1 Test Adjusted R-squared score: 0.786\n",
      "Fold 1 RMSE: 124353.574\n",
      "Fold 1 MAE: 72669.4375\n",
      "\n",
      "Fold 2 Test R-squared score: 0.9111\n",
      "Fold 2 Test Adjusted R-squared score: 0.9108\n",
      "Fold 2 RMSE: 79484.2227\n",
      "Fold 2 MAE: 49865.6236\n",
      "\n",
      "Fold 3 Test R-squared score: 0.9341\n",
      "Fold 3 Test Adjusted R-squared score: 0.9338\n",
      "Fold 3 RMSE: 70098.5645\n",
      "Fold 3 MAE: 44797.5931\n",
      "\n",
      "Fold 4 Test R-squared score: 0.9609\n",
      "Fold 4 Test Adjusted R-squared score: 0.9608\n",
      "Fold 4 RMSE: 53261.4921\n",
      "Fold 4 MAE: 35737.6749\n",
      "\n",
      "Fold 5 Test R-squared score: 0.9627\n",
      "Fold 5 Test Adjusted R-squared score: 0.9626\n",
      "Fold 5 RMSE: 53491.3803\n",
      "Fold 5 MAE: 33675.7578\n",
      "\n",
      "The average Train R-squared :  0.9585\n",
      "The average Test R-squared :  0.9111\n",
      "The average Test adjusted R-squared:  0.9108\n",
      "The average deviation from actual value (RMSE):  76137.8467\n",
      "The average deviation from actual value (MAE):  47349.2174\n",
      "Difference between Train vs. Test R-squared:  4.74 %\n"
     ]
    }
   ],
   "source": [
    "hgbr = HistGradientBoostingRegressor(learning_rate = 0.1, l2_regularization = 180, max_iter = 130)\n",
    "_ = price_ml(hgbr, original_train, original_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4faf4",
   "metadata": {},
   "source": [
    "### How about using an ann model for prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5fa5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_price_generator(input_shape):\n",
    "    T = input_shape\n",
    "    i = Input(shape = [T,])\n",
    "    x = Dense(400)(i)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(2000)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(400)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(inputs = i, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39e4f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Transform the dataset into the range 0-1 nad price to np.log(price)\n",
    "columns = ['livingAreaValue', 'lotArea', 'liv/lot_ratio', 'predicted_price/lotsqft', 'predicted_living_price',\n",
    "           'predicted_price1', 'predicted_price2']\n",
    "target = ['actual_price']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_price = dict()\n",
    "scaled_train_predict = dict()\n",
    "scaled_test_price = dict()\n",
    "scaled_test_predict = dict()\n",
    "\n",
    "n_folds = 5\n",
    "for i in range(n_folds):\n",
    "    train_set = original_train['Fold ' + str(i)][columns].copy().to_numpy()\n",
    "    train_predict = original_train['Fold ' + str(i)][target].copy().to_numpy()\n",
    "    test_set = original_test['Fold ' + str(i)][columns].copy().to_numpy()\n",
    "    test_predict = original_test['Fold ' + str(i)][target].copy().to_numpy()\n",
    "    \n",
    "    the_scaler1 = scaler\n",
    "    scaled_train_price['Fold ' + str(i)] = the_scaler1.fit_transform(train_set)\n",
    "    scaled_train_predict['Fold ' + str(i)] = np.log(train_predict).reshape(-1, 1)\n",
    "    scaled_test_price['Fold ' + str(i)] = the_scaler1.transform(test_set)\n",
    "    scaled_test_predict['Fold ' + str(i)] = np.log(test_predict).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b413e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test R-squared score: 0.796\n",
      "Fold 1 Test Adjusted R-squared score: 0.784\n",
      "Fold 1 RMSE: 121627.8765\n",
      "Fold 1 MAE: 71353.1529\n",
      "\n",
      "Fold 2 Test R-squared score: 0.914\n",
      "Fold 2 Test Adjusted R-squared score: 0.909\n",
      "Fold 2 RMSE: 78155.8432\n",
      "Fold 2 MAE: 48984.1934\n",
      "\n",
      "Fold 3 Test R-squared score: 0.9369\n",
      "Fold 3 Test Adjusted R-squared score: 0.9331\n",
      "Fold 3 RMSE: 68597.086\n",
      "Fold 3 MAE: 43601.4252\n",
      "\n",
      "Fold 4 Test R-squared score: 0.9623\n",
      "Fold 4 Test Adjusted R-squared score: 0.9601\n",
      "Fold 4 RMSE: 52284.1369\n",
      "Fold 4 MAE: 34558.841\n",
      "\n",
      "Fold 5 Test R-squared score: 0.9649\n",
      "Fold 5 Test Adjusted R-squared score: 0.9628\n",
      "Fold 5 RMSE: 51928.9208\n",
      "Fold 5 MAE: 33018.9664\n",
      "\n",
      "The average Train R-squared :  0.9479\n",
      "The average Test R-squared :  0.9148\n",
      "The average Test adjusted R-squared:  0.9098\n",
      "The average deviation from actual value (RMSE):  74518.7727\n",
      "The average deviation from actual value (MAE):  46303.3158\n",
      "Difference between Train vs. Test R-squared:  3.31 %\n"
     ]
    }
   ],
   "source": [
    "Test_R2_list = list()\n",
    "Test_adjusted_R2_list = list()\n",
    "Train_R2_list = list()\n",
    "rmse_list = list()\n",
    "mae_list = list()\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "input_shape = original_train['Fold 0'][columns].shape[1]\n",
    "model_price = ann_price_generator(input_shape)\n",
    "model_price.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "for i in range(5):\n",
    "    train = scaled_train_price['Fold ' + str(i)]\n",
    "    target_train = scaled_train_predict['Fold ' + str(i)]\n",
    "    test = scaled_test_price['Fold ' + str(i)]\n",
    "    target_test = scaled_test_predict['Fold ' + str(i)]\n",
    "\n",
    "    check_point = ModelCheckpoint('Monthly_combination_ANN/ANN_price/model_price_adam_ann_' + 'Fold ' + str(i) + '.h5', \n",
    "                                   monitor = 'val_mse', save_best_only = True)\n",
    "    model_price.fit(train, target_train, epochs = 80, validation_data = (test, target_test), \n",
    "                    batch_size = 32, callbacks = [check_point], verbose = 0)\n",
    "    model_allvars = tf.keras.models.load_model('Monthly_combination_ANN/ANN_price/model_price_adam_ann_' + 'Fold ' + str(i) + '.h5')\n",
    "    train_observed = original_train['Fold ' + str(i)][target].to_numpy().reshape(-1, 1)\n",
    "    train_predicted = np.exp(model_allvars.predict(train))\n",
    "    \n",
    "    ###We have calculated the actual price already with lot * price/lot\n",
    "    train_r_squared = r2_score(train_observed, train_predicted)\n",
    "    \n",
    "    ###For the test set\n",
    "    test_observed = original_test['Fold ' + str(i)][target].to_numpy().reshape(-1, 1)\n",
    "    test_predicted = np.exp(model_allvars.predict(test))   \n",
    "    test_r_squared = r2_score(test_observed, test_predicted)\n",
    "    \n",
    "    r2 = test_r_squared\n",
    "    n = test_observed.shape[0]\n",
    "    p = train_set2.shape[1]\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "    mse = mean_squared_error(test_observed, test_predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test_observed, test_predicted)\n",
    "\n",
    "    Test_R2_list.append(r2)\n",
    "    Test_adjusted_R2_list.append(adjusted_r2)\n",
    "    Train_R2_list.append(train_r_squared)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    \n",
    "    print(\"Fold \" + str(i + 1) + \" Test R-squared score:\", np.round(r2, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" Test Adjusted R-squared score:\", np.round(adjusted_r2, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" RMSE:\", np.round(rmse, 4))\n",
    "    print(\"Fold \" + str(i + 1) + \" MAE:\", np.round(mae, 4))\n",
    "    print()\n",
    "    \n",
    "dif = np.round(sum(Train_R2_list)/len(Train_R2_list), 4) - np.round(sum(Test_R2_list)/len(Test_R2_list), 4)\n",
    "dif = np.round(dif * 100, 2)\n",
    "print(\"The average Train R-squared : \", np.round(sum(Train_R2_list)/len(Train_R2_list), 4))\n",
    "print(\"The average Test R-squared : \", np.round(sum(Test_R2_list)/len(Test_R2_list), 4))\n",
    "print(\"The average Test adjusted R-squared: \", np.round(sum(Test_adjusted_R2_list)/len(Test_adjusted_R2_list), 4))\n",
    "print(\"The average deviation from actual value (RMSE): \", np.round(sum(rmse_list)/len(rmse_list), 4))\n",
    "print(\"The average deviation from actual value (MAE): \", np.round(sum(mae_list)/len(mae_list), 4))\n",
    "print(\"Difference between Train vs. Test R-squared: \", dif, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594366fe",
   "metadata": {},
   "source": [
    "# We will stick this architecture to predict house price\n",
    "1. Prep the data for DL\n",
    "2. Run ANN_location on location data to generate predicted price/lotArea\n",
    "3. Run ANN_properties on properties data to generate predicted living_price\n",
    "4. Run ANN_price to predict the price of the house with 2 predictions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1898ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow new)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
